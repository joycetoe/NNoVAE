{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "activate conda environment anopheles.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import sys\n",
    "\n",
    "import os, io, random\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import test files\n",
    "name='GCvalv1'\n",
    "manifestname = 'GCvalv1-meta.tsv'\n",
    "haplotypes = pd.read_csv(\"haplotypes-GCvalv1.tsv\", sep='\\t')\n",
    "meta = pd.read_csv(manifestname, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import reference files\n",
    "refbase = pd.read_csv(\"../../data/haplotypes/haplotypes-NNv1.csv\")\n",
    "td = pd.read_csv(\"../../analysis/1_species-groups-thresholds/sample_info.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up metadata and restrict to mosquitoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare numbers\n",
    "print(\"metadata table has \", meta[\"SUPPLIER SAMPLE NAME\"].nunique(), \" unique IDs, haplotypes has \", haplotypes.s_Sample.nunique(), ' unique IDs ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that haplotype IDs are contained and check which are the ones that fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isin(haplotypes.s_Sample.unique(), meta[\"SUPPLIER SAMPLE NAME\"].unique()).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.loc[~np.isin(meta[\"SUPPLIER SAMPLE NAME\"], haplotypes.s_Sample.unique())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ten fails are blank samples (one per plate)\n",
    "And another 13 mosquitoes failed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove plasmodium targets (should already be removed for the vignettes)\n",
    "haplotypes = haplotypes.loc[~haplotypes.target.isin(['P1', 'P2'])]\n",
    "haplotypes.target = haplotypes.target.astype('int')\n",
    "print(haplotypes.shape, haplotypes.s_Sample.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All uppercase\n",
    "print(haplotypes.shape)\n",
    "haplotypes['consensus'] = haplotypes['consensus'].str.upper()\n",
    "haplotypes = haplotypes.drop_duplicates()\n",
    "haplotypes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_kmer_dict(k):\n",
    "    labels = []\n",
    "    for i in itertools.product('ACGT', repeat=k):\n",
    "        labels.append(''.join(i))\n",
    "    kmerdict = dict(zip(labels, np.arange(4**k)))\n",
    "    return(kmerdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_combUID(haplotypes): \n",
    "    # assign IDs to unique sequences\n",
    "    combuids = dict()\n",
    "    for tgt, group in haplotypes.groupby(['target']):\n",
    "        for (i, cons) in enumerate(group['consensus'].unique()):\n",
    "            combuids[str(tgt)+cons] = '{}-{}'.format(tgt, i)\n",
    "    haplotypes['combUID'] = (haplotypes.target.astype('str') + haplotypes.consensus).replace(combuids)\n",
    "    return(haplotypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_kmer_table(k, seq, no_amp, x):\n",
    "    kmerdict = construct_kmer_dict(k)\n",
    "    table = np.zeros((no_amp, x, 4**k), dtype='int')\n",
    "    for r in seq.index:\n",
    "        combid = str.split(seq.loc[r,'combUID'], '-')\n",
    "        t, u = int(combid[0]), int(combid[1])\n",
    "        sq = seq.loc[r,'consensus']\n",
    "        for i in np.arange(len(sq)-(k-1)):\n",
    "            table[t,u,kmerdict[sq[i:i+k]]] += 1\n",
    "    return(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_unique_kmer_array(k, hap, no_amp):\n",
    "    # assign IDs to unique sequences if column combUID does not exist\n",
    "    if not 'combUID' in hap.columns:\n",
    "        hap = assign_combUID(hap)\n",
    "    \n",
    "    maxallele = hap.groupby('target')['combUID'].nunique().max()\n",
    "    \n",
    "    combUIDunique = hap[['combUID', 'consensus']].drop_duplicates()\n",
    "    \n",
    "    kmercombUID = sample_kmer_table(k, combUIDunique, no_amp, maxallele)\n",
    "    \n",
    "    return(kmercombUID, hap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main function\n",
    "#Currently very slow, look into how to speed up\n",
    "\n",
    "def clade_assignment(testseq, testkmers, refseq, refkmers, maxima, n_targets):\n",
    "    gps_coarse = refbase.coarse_sgp.cat.categories\n",
    "    gps_int = refbase.intermediate_sgp.cat.categories\n",
    "    gps_fine  = refbase.fine_sgp.cat.categories\n",
    "    \n",
    "    targets_per_sample = testseq.groupby('s_Sample')['target'].nunique()\n",
    "    testsamples = targets_per_sample[targets_per_sample>9].index\n",
    "    \n",
    "    #set up data-output (will be made into dataframes later)\n",
    "    res_coarse = np.zeros((n_targets, len(testsamples), len(gps_coarse)))\n",
    "    res_int = np.zeros((n_targets, len(testsamples), len(gps_int)))\n",
    "    res_fine = np.zeros((n_targets, len(testsamples), len(gps_fine)))\n",
    "    \n",
    "    #Split refseq into a dataframe per target\n",
    "    refseq_per_target = refseq.groupby('target')\n",
    "    \n",
    "    #Go through the test samples one by one\n",
    "    print(\"assign {} samples\".format(len(testsamples)))\n",
    "    for nsmp, smp in enumerate(testsamples):\n",
    "        #Restrict to amplified targets\n",
    "        targets = testseq.loc[testseq.s_Sample == smp, 'target'].unique()\n",
    "        \n",
    "        #Per amplified target\n",
    "        for t in targets:\n",
    "            #Per allele\n",
    "            alleles = testseq.loc[(testseq.s_Sample == smp) & (testseq.target == t), 'combUID']\n",
    "            for allele in alleles:\n",
    "                UID = int(allele.split('-')[1])\n",
    "                #Compute difference between target and references, with length correction\n",
    "                a = np.sum(np.abs(refkmers[t,:int(maxima[t]),:] - testkmers[t,UID,:]), axis=1)/ np.sum((refkmers[t,:int(maxima[t]),:] + testkmers[t,UID,:]), axis=1)\n",
    "                #Find minimal neighbours\n",
    "                cbn = np.arange(int(maxima[t]))[a==a.min()]\n",
    "                nncombuid = ['{}-{}'.format(t,x) for x in cbn]\n",
    "                #include neighbour column weighed by zygosity\n",
    "                refseq_t = refseq_per_target.get_group(t).copy()\n",
    "                nndict = dict(refseq_t['combUID'].isin(nncombuid)*refseq_t['zygosity'])\n",
    "                refseq_t['neighbours'] = refseq_t.index.map(nndict)\n",
    "                \n",
    "                #Now store assignment scores proportional to allele frequency\n",
    "                for level, table in zip(['fine_sgp', 'intermediate_sgp', 'coarse_sgp'], [res_fine, res_int, res_coarse]):\n",
    "                    #per level, compute the neighbour allele frequency\n",
    "                    #because refseq is categorical, it should record all levels in the same order\n",
    "                    nsum = refseq_t.groupby(level)['neighbours'].sum()\n",
    "                    zsum = refseq_t.groupby(level)['zygosity'].sum()\n",
    "                    nb = nsum/zsum\n",
    "                    #normalise such that per sample neighbour frequency is 2 (diploid)\n",
    "                    table[t,nsmp,:] += (2/len(alleles))*nb/np.sum(nb)\n",
    "        if nsmp % 20 == 0:\n",
    "            print(\"sample {} done\".format(nsmp))\n",
    "  \n",
    "    #Save per target assigments for future reference\n",
    "    np.save(\"assignment_fine_per_target.npy\", res_fine)\n",
    "    np.save(\"assignment_intermediate_per_target.npy\", res_int)\n",
    "    np.save(\"assignment_coarse_per_target.npy\", res_coarse)\n",
    "    \n",
    "    #Make result tables into dataframes\n",
    "    rc = np.nansum(res_coarse, axis=0)/np.sum(np.nansum(res_coarse, axis=0), axis=1)[:,None]\n",
    "    result_coarse = pd.DataFrame(rc, index=testsamples, columns=refbase.coarse_sgp.cat.categories)\n",
    "    result_coarse.to_csv(\"assignment_coarse.csv\")\n",
    "    ri = np.nansum(res_int, axis=0)/np.sum(np.nansum(res_int, axis=0), axis=1)[:,None]\n",
    "    result_intermediate = pd.DataFrame(ri, index=testsamples, columns=refbase.intermediate_sgp.cat.categories)\n",
    "    result_intermediate.to_csv(\"assignment_intermediate.csv\")\n",
    "    rf = np.nansum(res_fine, axis=0)/np.sum(np.nansum(res_fine, axis=0), axis=1)[:,None]\n",
    "    result_fine = pd.DataFrame(rf, index=testsamples, columns=refbase.fine_sgp.cat.categories)\n",
    "    result_fine.to_csv(\"assignment_fine.csv\")\n",
    "        \n",
    "    return(result_coarse, result_intermediate, result_fine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataprep refset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign combUIDs to refdatabase\n",
    "refbase = assign_combUID(refbase)\n",
    "#Add column with zygosity information\n",
    "#Add allelic zygosity\n",
    "zygosity = 2/refbase.groupby(['s_Sample', 'target'])['combUID'].nunique()\n",
    "zygosity = pd.DataFrame(zygosity).reset_index()\n",
    "zygosity_dict = dict(zip(zygosity.s_Sample + zygosity.target.astype('str'), zygosity.combUID))\n",
    "refbase['zygosity'] = (refbase.s_Sample + refbase.target.astype('str')).replace(zygosity_dict)\n",
    "#Check that all samples sum to 2\n",
    "(refbase.groupby(['s_Sample', 'target'])['zygosity'].sum()==2).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Include group information in refbase dataframe\n",
    "tdfdict = dict(zip(td.index, td.fine_sgp))\n",
    "tdidict = dict(zip(td.index, td.intermediate_sgp))\n",
    "tdcdict = dict(zip(td.index, td.coarse_sgp))\n",
    "refbase['fine_sgp'] = refbase.s_Sample.map(tdfdict)\n",
    "refbase['intermediate_sgp'] = refbase.s_Sample.map(tdidict)\n",
    "refbase['coarse_sgp'] = refbase.s_Sample.map(tdcdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make refbase entries categorical\n",
    "refbase['fine_sgp'] = pd.Categorical(refbase['fine_sgp'], ['Anopheles_marshallii_complex', 'Anopheles_marshallii_cp_sp1',\n",
    "       'Anopheles_theileri', 'Anopheles_moucheti', 'Anopheles_jebudensis',\n",
    "       'Myzomyia_sp1', 'Anopheles_gabonensis', 'Anopheles_funestus',\n",
    "       'Anopheles_rhodesiensis', 'Anopheles_minimus_A',\n",
    "       'Anopheles_culicifacies', 'Anopheles_aconitus', 'Anopheles_rampae',\n",
    "       'Anopheles_maculatus_A', 'Anopheles_maculatus_B',\n",
    "       'Anopheles_maculipalpis', 'Anopheles_annularis',\n",
    "       'Anopheles_jamesii', 'Anopheles_stephensi',\n",
    "       'Anopheles_gambiae_coluzzii', 'Anopheles_arabiensis',\n",
    "       'Anopheles_gambiae_cp_sp1', 'Anopheles_quadriannulatus',\n",
    "       'Anopheles_melas', 'Anopheles_merus', 'Anopheles_christyi',\n",
    "       'Anopheles_sundaicus_complex', 'Anopheles_vagus',\n",
    "       'Anopheles_dirus_A', 'Anopheles_balabacensis', 'Anopheles_cracens',\n",
    "       'Anopheles_koliensis', 'Anopheles_farauti',\n",
    "       'Anopheles_punctulatus', 'Anopheles_tessellatus',\n",
    "       'Anopheles_coustani_cp_cl3', 'Anopheles_coustani_cp_cl2', \n",
    "       'Anopheles_coustani_cp_cl1', 'Anopheles_hyrcanus_gp_sp1', \n",
    "       'Anopheles_hyrcanus_gp_sp2', 'Anopheles_sinensis',\n",
    "       'Anopheles_barbirostris', 'Anopheles_atroparvus',\n",
    "       'Anopheles_implexus', 'Anopheles_nili_gp_sp3',\n",
    "       'Anopheles_nili_gp_sp2', 'Anopheles_nili_gp_sp1',\n",
    "       'Anopheles_carnevalei', 'Anopheles_vinckei', 'Anopheles_dureni',\n",
    "       'Anopheles_aquasalis', 'Anopheles_oryzalimnetes',\n",
    "       'Anopheles_darlingi', 'Anopheles_albimanus', 'Anopheles_cruzii',\n",
    "       'Anopheles_bellator'], ordered=True)\n",
    "refbase['intermediate_sgp'] = pd.Categorical(refbase['intermediate_sgp'],['Anopheles_marshallii_group', 'Anopheles_moucheti_group',\n",
    "       'Myzomyia_sp1', 'Anopheles_gabonensis', 'Anopheles_funestus',\n",
    "       'Anopheles_rhodesiensis', 'Anopheles_minimus_A',\n",
    "       'Anopheles_culicifacies', 'Anopheles_aconitus',\n",
    "       'Anopheles_maculatus_group', 'Anopheles_maculipalpis',\n",
    "       'Anopheles_annularis', 'Anopheles_jamesii', 'Anopheles_stephensi',\n",
    "       'Anopheles_gambiae_complex', 'Anopheles_christyi',\n",
    "       'Anopheles_sundaicus_complex', 'Anopheles_vagus',\n",
    "       'Anopheles_dirus_complex', 'Anopheles_punctulatus_group',\n",
    "       'Anopheles_tessellatus', 'Anopheles_coustani_complex',\n",
    "       'Anopheles_hyrcanus_gp_sp1', 'Anopheles_sinensis_group',\n",
    "       'Anopheles_barbirostris', 'Anopheles_atroparvus',\n",
    "       'Anopheles_implexus', 'Anopheles_nili_group', 'Anopheles_vinckei',\n",
    "       'Anopheles_dureni', 'Anopheles_aquasalis',\n",
    "       'Anopheles_oryzalimnetes', 'Anopheles_darlingi',\n",
    "       'Anopheles_albimanus', 'Kerteszia_subgenus'], ordered=True)\n",
    "refbase['coarse_sgp'] = pd.Categorical(refbase['coarse_sgp'], ['Myzomyia_Neocellia_series', 'Pyretophorus_series',\n",
    "       'Neomyzomyia_series_I', 'Myzorhynchus_series', 'Christya_series',\n",
    "       'Neomyzomyia_series_II', 'Neomyzomyia_series_III',\n",
    "       'Nyssorhynchus_subgenus', 'Kerteszia_subgenus'], ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show refbase\n",
    "refbase.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make unique k-mer table for the reference base\n",
    "ref8mers, refbase = construct_unique_kmer_array(k=8, hap=refbase, no_amp=62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Record number of unique k-mers per target for refset\n",
    "maxima = refbase.groupby('target')['combUID'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataprep testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test8mers, haplotypes = construct_unique_kmer_array(k=8, hap=haplotypes, no_amp=62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_coarse, result_intermediate, result_fine = clade_assignment(testseq=haplotypes, testkmers=test8mers, refseq=refbase, \n",
    "                                                                   refkmers=ref8mers, maxima=maxima, n_targets=62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Produce hard calls\n",
    "meta.loc[meta.s_Sample.isin(result_coarse.index), 'assigned'] = True\n",
    "for result, rescol in zip([result_coarse, result_intermediate, result_fine], ['res_coarse', 'res_int', 'res_fine']):\n",
    "    adict = dict(result.loc[(result>=.8).any(axis=1)].apply(lambda row: result.columns[row>=0.8][0], axis=1))\n",
    "    meta[rescol] = meta.s_Sample.map(adict)\n",
    "meta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect other statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetdict = dict(haplotypes.groupby(['s_Sample'])['target'].nunique())\n",
    "readdict = dict(haplotypes.groupby(['s_Sample'])['reads'].sum())\n",
    "alleledict = dict(pd.DataFrame(haplotypes.groupby(['s_Sample', 'target'])['consensus'].nunique()).reset_index().groupby(['s_Sample'])['consensus'].mean())\n",
    "multidict = dict(pd.DataFrame(haplotypes.groupby(['s_Sample', 'target'])['consensus'].nunique()>2).reset_index().groupby(['s_Sample'])['consensus'].sum())\n",
    "\n",
    "meta['n_mosquito_targets'] = meta['SUPPLIER SAMPLE NAME'].map(targetdict)\n",
    "meta['mosquito_reads'] = meta['SUPPLIER SAMPLE NAME'].map(readdict)\n",
    "meta['mean_mosquito_haps'] = meta['SUPPLIER SAMPLE NAME'].map(alleledict)\n",
    "meta['n_multiallelic'] = meta['SUPPLIER SAMPLE NAME'].map(multidict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.to_csv('{}_results.tsv'.format(name), sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect gambiae complex samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Restrict to gambiae complex\n",
    "metagam = meta.loc[meta.res_int=='Anopheles_gambiae_complex']\n",
    "gamsamples = metagam['SUPPLIER SAMPLE NAME']\n",
    "hapgam = haplotypes.loc[haplotypes.s_Sample.isin(gamsamples)]\n",
    "print(metagam.shape, hapgam.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct per sample kmer table\n",
    "#This includes samples with between 10 and 50 targets\n",
    "#We project those onto latent space, but currently we don't assign them with the Convex Hulls\n",
    "#Because the assignment is too affected by the lower coverage\n",
    "k=8\n",
    "no_amp=62\n",
    "\n",
    "table = np.zeros((len(gamsamples), 4**k), dtype='int')\n",
    "\n",
    "for e, smp in enumerate(gamsamples):\n",
    "    smptable = np.zeros((no_amp, 4**k))\n",
    "    smpseq = seq.loc[seq.s_Sample == smp]\n",
    "    hapcopies = np.zeros(a)\n",
    "    for r in smpseq.index:\n",
    "        combUID = smpseq.loc[r, 'combUID']\n",
    "        t, u = int(str.split(combUID, '-')[0]), int(str.split(combUID, '-')[1])\n",
    "        if hapcopies[t] < 2:\n",
    "            smptable[t,:] += kmer8[t, u, :]\n",
    "            hapcopies[t] += 1\n",
    "    for t in np.arange(a):\n",
    "        #double homozygotes\n",
    "        if hapcopies[t] == 1:\n",
    "            smptable[t,:] *= 2\n",
    "    table[e,:] = np.sum(smptable, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metagam[['SUPPLIER SAMPLE NAME', 'n_mosquito_targets']].to_csv(\"gambiae_complex/samples.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"gambiae_complex/kmers.npy\", table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAE assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, run project the gambiae samples onto latent space using the notebook analysis/3_gambiae-complex-VAE/2_project_to_LS.ipynb, putting '../../tracking/Burkina-Faso/' as out. This will create a file gambiae_complex/latent_coords.csv containing the sample coordinates in VAE space. WARNING: this file also contains lower coverage samples (10 to 49 targets). For classification with Convex Hulls (next step) and plotting, you probably want to restrict to samples with at least 50 targets.\n",
    "\n",
    "Then, classify species using the notebook analysis/4_Convex-Hull-assignments/1_assign_species.ipynb, setting '../../tracking/Burkina-Faso' as tracking_dir. This notebook subsets to high coverage samples (at least 50 targets) by default. This will create a file gambiae_complex/GC_assignments.tsv containing the assigned species label for the gambiae complex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined species calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamcalls = pd.read_csv(\"gambiae_complex/GC_assignments.tsv\", sep='\\t')\n",
    "gamcalls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamspdict = dict(zip(gamcalls.sample_id, gamcalls.assigned_species))\n",
    "meta['VAE_species'] = meta['SUPPLIER SAMPLE NAME'].map(gamspdict)\n",
    "meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy vae species\n",
    "meta['species_call'] = meta['SUPPLIER SAMPLE NAME'].map(gamspdict)\n",
    "meta.loc[~meta.species_call.isnull(), 'call_method'] = 'VAE'\n",
    "\n",
    "#copy res_fine\n",
    "finedict = dict(zip(meta['SUPPLIER SAMPLE NAME'], meta['res_fine']))\n",
    "meta.loc[(meta.species_call.isnull()) & ~(meta.res_fine.isnull()), 'call_method'] = 'NN_FINE'\n",
    "meta.loc[(meta.species_call.isnull()) & ~(meta.res_fine.isnull()), 'species_call'] = meta.loc[(meta.species_call.isnull()) \n",
    "                                                        & ~(meta.res_fine.isnull()), 'SUPPLIER SAMPLE NAME'].map(finedict)\n",
    "#copy res_int\n",
    "intdict = dict(zip(meta['SUPPLIER SAMPLE NAME'], meta['res_int']))\n",
    "meta.loc[(meta.species_call.isnull()) & ~(meta.res_int.isnull()), 'call_method'] = 'NN_INTERMEDIATE'\n",
    "meta.loc[(meta.species_call.isnull()) & ~(meta.res_int.isnull()), 'species_call'] = meta.loc[(meta.species_call.isnull()) \n",
    "                                                            & ~(meta.res_int.isnull()), 'SUPPLIER SAMPLE NAME'].map(intdict)\n",
    "#copy res_coarse\n",
    "coarsedict = dict(zip(meta['SUPPLIER SAMPLE NAME'], meta['res_coarse']))\n",
    "meta.loc[(meta.species_call.isnull()) & ~(meta.res_coarse.isnull()), 'call_method'] = 'NN_COARSE'\n",
    "meta.loc[(meta.species_call.isnull()) & ~(meta.res_coarse.isnull()), 'species_call'] = meta.loc[(meta.species_call.isnull()) \n",
    "                                                        & ~(meta.res_coarse.isnull()), 'SUPPLIER SAMPLE NAME'].map(coarsedict)\n",
    "#rainbow samples\n",
    "meta.loc[(meta.species_call.isnull()) & (meta.assigned==True), 'call_method'] == 'NN'\n",
    "meta.loc[(meta.species_call.isnull()) & (meta.assigned==True), 'species_call'] = 'RAINBOW_SAMPLE'\n",
    "#too few targets\n",
    "meta.loc[(meta.assigned.isnull()), 'species_call'] = 'TOO_FEW_TARGETS'\n",
    "meta.loc[(meta.assigned.isnull()), 'call_method'] = 'TOO_FEW_TARGETS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.groupby(['SCIENTIFIC_NAME', 'assigned', \n",
    "                  'species_call', 'call_method'], dropna=False)['SUPPLIER SAMPLE NAME'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta= meta.set_index('SUPPLIER SAMPLE NAME')\n",
    "meta.to_csv(\"{}_results.tsv\".format(name), sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot NN assignment results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pick unique colors for each of the fine assignment categories\n",
    "turquoise = np.concatenate([plt.cm.Dark2(np.arange(8))[:1], plt.cm.Set2(np.arange(8))[:1], plt.cm.Set3(np.arange(12))[:1], plt.cm.Pastel2(np.arange(8))[:1]])\n",
    "yellows = np.concatenate([plt.cm.Set2(np.arange(8))[5:6], plt.cm.Set3(np.arange(12))[11:], plt.cm.Set1(np.arange(9))[5:6], plt.cm.Set3(np.arange(12))[1:2]])\n",
    "blues = np.array([[5,8,84,200], [12,16,148,200], [0,8,255,200], [52,82,235,200]])/256\n",
    "browns =  np.array([[56,22,6,200], [125,45,5,200], [148,67,27,200], [194, 72, 12, 200]])/256 \n",
    "colorsb = plt.cm.tab20b(np.arange(20))\n",
    "colorsc = plt.cm.tab20c(np.arange(20))\n",
    "colors = np.concatenate([colorsb, colorsc, turquoise, yellows, blues, browns])\n",
    "colors30 = np.delete(colors, [1,2,4,13,14,19,21,22,23,24,29,30,31,33,35,38,39,45,46,47,54], axis=0)\n",
    "colors51 = colors[[17, 20, 28, 36, 43, 44, 48, 51, 55 ],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level='coarse'\n",
    "assignment = result_coarse\n",
    "levelcolor=colors51\n",
    "fig, ax = plt.subplots(figsize=(20,7))\n",
    "assignment.plot(kind='bar', stacked=True, width=1, ax=ax, color=levelcolor)\n",
    "ax.set_xticklabels('')\n",
    "ax.set_xticks([])\n",
    "ax.set_title(\"{} level assignment\".format(level))\n",
    "ax.hlines(.8, -.5, assignment.shape[0]-.5, color='k', ls = ':', linewidth=1)\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0, box.y0+3/7*box.height, box.width, box.height*4/7])\n",
    "leg1 = ax.legend(loc='upper center', ncol=7, bbox_to_anchor=(0.5, -.05), fontsize=8.7)\n",
    "ax.margins(y=0)\n",
    "plt.savefig(out+\"plot_{}_assignment.png\".format(level))\n",
    "plt.savefig(out+\"plot{}_assignment.pdf\".format(level))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level='int'\n",
    "assignment = result_intermediate\n",
    "levelcolor=colors30\n",
    "fig, ax = plt.subplots(figsize=(20,7))\n",
    "assignment.plot(kind='bar', stacked=True, width=1, ax=ax, color=levelcolor)\n",
    "ax.set_xticklabels('')\n",
    "ax.set_xticks([])\n",
    "ax.set_title(\"{} level assignment\".format(level))\n",
    "ax.hlines(.8, -.5, assignment.shape[0]-.5, color='k', ls = ':', linewidth=1)\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0, box.y0+3/7*box.height, box.width, box.height*4/7])\n",
    "leg1 = ax.legend(loc='upper center', ncol=7, bbox_to_anchor=(0.5, -.05), fontsize=8.7)\n",
    "ax.margins(y=0)\n",
    "plt.savefig(out+\"plot_{}_assignment.png\".format(level))\n",
    "plt.savefig(out+\"plot{}_assignment.pdf\".format(level))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level='fine'\n",
    "assignment = result_fine\n",
    "levelcolor=colors\n",
    "fig, ax = plt.subplots(figsize=(20,7))\n",
    "assignment.plot(kind='bar', stacked=True, width=1, ax=ax, color=levelcolor)\n",
    "ax.set_xticklabels('')\n",
    "ax.set_xticks([])\n",
    "ax.set_title(\"{} level assignment\".format(level))\n",
    "ax.hlines(.8, -.5, assignment.shape[0]-.5, color='k', ls = ':', linewidth=1)\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0, box.y0+3/7*box.height, box.width, box.height*4/7])\n",
    "leg1 = ax.legend(loc='upper center', ncol=7, bbox_to_anchor=(0.5, -.05), fontsize=8.7)\n",
    "ax.margins(y=0)\n",
    "plt.savefig(out+\"plot_{}_assignment.png\".format(level))\n",
    "plt.savefig(out+\"plot{}_assignment.pdf\".format(level))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
